{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Exam Study Guide\n",
    "\n",
    "In general, you are responsible for content from lectures 1-4 as well as homeworks, case studies, and the practice midterm. The topics covered will include:\n",
    "\n",
    "* Data organization and processing\n",
    "* Basic concepts in machine learning\n",
    "* Generalized linear models for regression\n",
    "    - multi-linear regression with non-linear features\n",
    "    - kernel ridge regression\n",
    "* Generalized linear models for classification\n",
    "    - logistic regression\n",
    "    - support vector machines\n",
    "    - kernel support vector machines\n",
    "* Principal component analysis\n",
    "* k-Nearest Neighbors\n",
    "\n",
    "In particular, you should ensure that you are familiar with the following concpets/definitions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Concepts\n",
    "\n",
    "* Preparing data for application of models\n",
    "    - creating structured and consistent input data\n",
    "    - converting to appropriate data types\n",
    "    - evaluating and removing covariance of features\n",
    "\n",
    "* Relationship between generalized linear models\n",
    "    - changing the cost function\n",
    "    - adding non-linear features (parametric and non-parametric)\n",
    "    - regularization of the cost function\n",
    "    - optimization of the cost function\n",
    "    \n",
    "* Optimizing complexity through hyper-parameter tuning\n",
    "    - using test/train splits to evaluate best hyperparameters\n",
    "    - understanding the tradeoff between underfitting and overfitting\n",
    "    \n",
    "* Selecting appropriate models based on the nature of a problem or dataset\n",
    "    - analyzing the inputs/outputs to identify class of algorithm needed\n",
    "    - assessing the nature of the data distributions (classification) or residual distributions (regression) to determine specific algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions:\n",
    "\n",
    "You should know the definitions of the following terms:\n",
    "\n",
    "* structured data and unstructured data\n",
    "* metadata\n",
    "* API\n",
    "* features\n",
    "* derived features\n",
    "* parameters\n",
    "* hyperparameters\n",
    "* supervised and unsupervised learning\n",
    "* regression\n",
    "* classification\n",
    "* clustering\n",
    "* dimensional reduction\n",
    "* parametric vs. non-parametric models\n",
    "* overfitting and underfitting\n",
    "* cross validation\n",
    "* eigenvalues and eigenvectors\n",
    "* objective function\n",
    "* lineary independence vs. co-linear\n",
    "* covariance matrix\n",
    "* regularization\n",
    "* homoskedastic vs. heteroskedastic\n",
    "* parity plot\n",
    "* generalized linear model\n",
    "* non-linear features vs. non-linear model\n",
    "* discriminative vs. generative models\n",
    "* decision boundary\n",
    "* linearly separable\n",
    "* class imbalance\n",
    "* binary vs. multiclass problems\n",
    "* accuracy, precision, and recall\n",
    "* confusion matrix\n",
    "* ROC curves\n",
    "* perceptron (max cost)\n",
    "* logistic regression (softmax)\n",
    "* support vector machine (margin)\n",
    "* kernel\n",
    "* Gaussian distribution\n",
    "* intraclass vs. interclass variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming\n",
    "\n",
    "You should be familiar with the following programming tasks\n",
    "\n",
    "* indexing `numpy` arrays and `pandas` dataframes\n",
    "* converting data types\n",
    "* basic linear algebra using `numpy` functions (matrix vector multiplication, transpose, inverse, eigendecomposition)\n",
    "* numerical optimization of functions using `scipy`\n",
    "* application of basic machine-learning algorithms with `scikit-learn` implementations\n",
    "* combining existing functions to implement simple algorithms\n",
    "    - combine covariance and eigendecomposition to perform PCA\n",
    "    - combine distance metric and nearest neighbors to implement kNN\n",
    "    - combine cost function and numerical optimizer to perform logistic regression\n",
    "* hyperparameter optimization using cross-validation from `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematics\n",
    "\n",
    "You should know how to derive generalized linear models from an associated cost function. You should know basic linear algebra manipulations, but matrix/vector derivatives and necessary identities will be provided. You should also understand the mathematical connection between parameters and best-fit lines (regression) and decision boundaries (classification) for generalized linear models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
